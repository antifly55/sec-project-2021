import hashlib
import numpy as np
import ujson as json

def read_json(path):
    with open(path, "r") as f:
        return json.load(f)

class FHargs:
    coff = 64
    optional = 64
    import_dll = 512
    import_func = 8192
    import_func2 = 1024
    export = 512
    string = 8192
    entry = 64
    sections = 1024

def FeatureHashing(features, dim):
    vector = [0] * dim
    for feature in features:
        digest = int(hashlib.md5(feature.encode()).hexdigest(), 16) % dim
        vector[digest] += 1
    return vector

def get_coff_info(report):
    header = report["header"]["coff"]
    words = header["characteristics"]
    words.append(header["machine"])
    return FeatureHashing(words, FHargs.coff)

def get_optional_info(report):
    header = report["header"]["optional"]
    words = header["dll_characteristics"]
    words.append(header["subsystem"])
    words.append(header["magic"])
    vector = FeatureHashing(words, FHargs.optional)
    vector += [
        header['major_image_version'], header['minor_image_version'], header['major_linker_version'],
        header['minor_linker_version'], header['major_operating_system_version'], header['minor_operating_system_version'],
        header['major_subsystem_version'], header['minor_subsystem_version'], header['sizeof_code'],
        header['sizeof_headers'], header['sizeof_heap_commit']
    ]
    return vector

def get_imports_info(report):
    imports = report['imports']
    vector_dll = []
    vector_func = []
    vector_func2 = []
    for dll in imports.keys():
        vector_dll.append(dll)
        for func in imports[dll]:
            vector_func.append(dll + func)
            vector_func2.append(func)
    return FeatureHashing(vector_dll, FHargs.import_dll) + FeatureHashing(vector_func, FHargs.import_func) + FeatureHashing(vector_func2, FHargs.import_func2)

def get_exports_info(report):
    exports = report['exports']
    return FeatureHashing(exports, FHargs.export)

def get_general_file_info(report):
    general = report["general"]
    vector = [
        general['size'], general['vsize'], general['has_debug'], general['exports'], general['imports'],
        general['has_relocations'], general['has_resources'], general['has_signature'], general['has_tls'],
        general['symbols']
    ]
    return vector

def get_string_info(report):
    strings = report["strings"]

    hist_divisor = float(strings['printables']) if strings['printables'] > 0 else 1.0
    vector = [
        strings['numstrings'], 
        strings['avlength'], 
        strings['printables'],
        strings['entropy'], 
        strings['paths'], 
        strings['urls'],
        strings['registry'], 
        strings['MZ']
    ]
    vector += (np.asarray(strings['printabledist']) / hist_divisor).tolist()
    return vector

def get_histogram_info(report):
    histogram = np.array(report["histogram"], dtype = float)
    total = histogram.sum()
    vector = histogram / total
    return vector.tolist()

def get_byteentropy_info(report):
    histogram = np.array(report["byteentropy"], dtype = float)
    total = histogram.sum()
    vector = histogram / total
    return vector.tolist()

def get_sections_info(report):
    sections = report['section']['sections']
    
    list_size = []
    list_vsize = []
    list_entropy = []
    list_props = []
    
    num_of_zero = 0
    num_of_noname = 0
    num_of_re = 0
    num_of_w = 0
    
    for section in sections:
        if section['size'] == 0:
            num_of_zero += 1
        if 'name' not in section.keys() or len(section['name'])==0:
            num_of_noname += 1
        if 'MEM_READ' in section['props'] and 'MEM_WRITE' in section['props']:
            num_of_re += 1
        if 'MEM_WRITE' in section['props']:
            num_of_w += 1
            
        list_size.append(section['size'])
        list_vsize.append(section['vsize'])
        list_entropy.append(section['entropy'])
        list_props += section['props']
        
    list_size.sort()
    list_vsize.sort()
    list_entropy.sort()
    
    if len(list_size) == 0:
        list_size.append(0)
    if len(list_vsize) == 0:
        list_vsize.append(0)
    if len(list_entropy) == 0:
        list_entropy.append(0)
    
    vector = FeatureHashing(list_props, FHargs.sections)
    vector += [len(sections), num_of_zero, num_of_noname, num_of_re, num_of_w]
    vector += [
        min(list_size), max(list_size), list_size[len(list_size)//2], sum(list_size)/len(list_size), 
        min(list_vsize), max(list_vsize), list_vsize[len(list_vsize)//2], sum(list_vsize)/len(list_vsize), 
        min(list_entropy), max(list_entropy), list_entropy[len(list_entropy)//2], sum(list_entropy)/len(list_entropy)
    ]
    vector += FeatureHashing([report['section']['entry']], FHargs.entry)
    
    return vector

directory_list = {
    "EXPORT_TABLE",
    "IMPORT_TABLE",
    "RESOURCE_TABLE",
    "EXCEPTION_TABLE",
    "CERTIFICATE_TABLE",
    "BASE_RELOCATION_TABLE",
    "DEBUG",
    "ARCHITECTURE",
    "GLOBAL_PTR",
    "TLS_TABLE",
    "LOAD_CONFIG_TABLE",
    "BOUND_IMPORT",
    "IAT",
    "DELAY_IMPORT_DESCRIPTOR",
    "CLR_RUNTIME_HEADER"
}

def get_directory_info(report):
    datadirectories = report['datadirectories']
    
    bundle = dict()
    for data in datadirectories:
        bundle[data['name']] = data
    
    vector = []
    for func in directory_list:
        size, va = 0, 0
        if func in bundle.keys():
            size, va = bundle[func]['size'], bundle[func]['virtual_address']
        vector += [size, va]

    return vector

def PeminerFeatureExtract(path):
    report = read_json(path)
    vector = [value for _, value in sorted(report.items(), key=lambda x: x[0])]
    return vector

def EmberFeatureExtract(path):
    report = read_json(path)
    vector = []
    vector += get_general_file_info(report)
    vector += get_histogram_info(report)
    vector += get_string_info(report)
    vector += get_coff_info(report)
    vector += get_optional_info(report)
    vector += get_byteentropy_info(report)
    vector += get_imports_info(report)
    vector += get_exports_info(report)
    vector += get_directory_info(report)
    vector += get_sections_info(report)
    return vector

def PestudioFeatureExtract(path):

    report = read_json(path)
    strings = report['image']['strings']

    vector = [
        int(strings['@bl']), int(strings['@count'])
    ]
    words = []

    if 'ascii' in strings.keys() and strings['ascii'] != None:
        vector.append(int(strings['ascii']['@count']))
        if vector[-1] == 1:
            words.append(strings['ascii']['string']['#text'])
        else:
            for text in strings['ascii']['string']:
                if '#text' in text.keys():
                    words.append(text['#text'])
    else:
        vector.append(0)

    if 'unicode' in strings.keys() and strings['unicode'] != None:
        vector.append(int(strings['unicode']['@count']))
        if vector[-1] == 1:
            words.append(strings['unicode']['string']['#text'])
        else:
            for text in strings['unicode']['string']:
                if '#text' in text.keys():
                    words.append(text['#text'])
    else:
        vector.append(0)

    vector += FeatureHashing(words, FHargs.string)
    
    return vector
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sec1-pipeline.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpHKjsBLOOEU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "412a07ca-b999-4e98-a55a-0901120f27a6"
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "try:\n",
        "  os.chdir('./drive/MyDrive/weblog')\n",
        "except:\n",
        "  pass"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlfjCfuhxlek"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBLBA5PmtSHd"
      },
      "source": [
        "def featureExtract(filepath):\n",
        "\n",
        "  f = open(filepath)\n",
        "  a = f.readlines()\n",
        "\n",
        "  features = []\n",
        "  feature = None\n",
        "  \n",
        "  for i in range(len(a)):\n",
        "    line = a[i]\n",
        "    line = line.rstrip()\n",
        "    if line[:4] in ['GET ', 'POST', 'PUT ']:\n",
        "\n",
        "      if feature != None:\n",
        "        features.append(feature)\n",
        "        feature = None\n",
        "\n",
        "      chunks = line.split()\n",
        "      feature = ''\n",
        "\n",
        "      urls = chunks[1].replace('//', '/').split('/')\n",
        "      for i in range(len(urls)-1):\n",
        "        tmp = urls[i] + urls[i+1]\n",
        "        feature += ' ' + tmp\n",
        "\n",
        "    elif line.startswith('Content-Length:'):\n",
        "      body = a[i+2].rstrip().split('&')\n",
        "      for i in range(len(body)):\n",
        "        tmp = body[i].split('=')\n",
        "        feature += ' ' + tmp[0]\n",
        "        feature += ' ' + tmp[1]\n",
        "\n",
        "  if feature != None:\n",
        "    features.append(feature)\n",
        "    feature = None\n",
        "\n",
        "  return features"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gULS58wxEn6s"
      },
      "source": [
        "def anomalyExtract(filepath):\n",
        "\n",
        "  f = open(filepath)\n",
        "  a = f.readlines()\n",
        "\n",
        "  judge = []\n",
        "  pred = None\n",
        "  \n",
        "  for i in range(len(a)):\n",
        "\n",
        "    line = a[i].rstrip()\n",
        "    if line[:4] in ['GET ', 'POST', 'PUT ']:\n",
        "\n",
        "      if pred != None:\n",
        "        judge.append(pred)\n",
        "        pred = None\n",
        "\n",
        "      chunks = line.split()\n",
        "      pred = 0\n",
        "\n",
        "    elif line.startswith('Host:') and 'localhost:9090' in line:\n",
        "        pred = 1\n",
        "\n",
        "  if pred != None:\n",
        "    judge.append(pred)\n",
        "    pred = None\n",
        "\n",
        "  return judge"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OancNfFjwsHD"
      },
      "source": [
        "feature1 = featureExtract('norm_train.txt')\n",
        "feature2 = featureExtract('norm_test.txt')\n",
        "feature3 = featureExtract('anomal_train.txt')\n",
        "feature4 = featureExtract('anomal_test.txt')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_YKYMyYEEtei"
      },
      "source": [
        "anomal1 = anomalyExtract('norm_train.txt')\n",
        "anomal2 = anomalyExtract('norm_test.txt')\n",
        "anomal3 = anomalyExtract('anomal_train.txt')\n",
        "anomal4 = anomalyExtract('anomal_test.txt')\n",
        "\n",
        "anomal_train = anomal1 + anomal3\n",
        "anomal_test = anomal2 + anomal4"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgFkypy7x2mf"
      },
      "source": [
        "trainX = feature1 + feature3\n",
        "trainY = [0] * len(feature1) + [1] * len(feature3)\n",
        "\n",
        "testX = feature2 + feature4\n",
        "testY = [0] * len(feature2) + [1] * len(feature4)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DMhzjdCuw53"
      },
      "source": [
        "vectorizer = TfidfVectorizer(min_df=0.0, analyzer=\"word\", sublinear_tf=True, ngram_range=(1, 1))\n",
        "trainX = vectorizer.fit_transform(trainX)\n",
        "testX = vectorizer.transform(testX)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21u6uFtwJtGY"
      },
      "source": [
        "def train_and_test(model):\n",
        "  model.fit(trainX, trainY)\n",
        "  predY = model.predict(testX)\n",
        "\n",
        "  for i in range(len(predY)):\n",
        "    predY[i] |= anomal_test[i]\n",
        "\n",
        "  print(\"Accuracy:\", accuracy_score(testY, predY))\n",
        "  print(\"Precision:\", precision_score(testY, predY))\n",
        "  print(\"Recall:\", recall_score(testY, predY))\n",
        "  print(\"F1Score:\", f1_score(testY, predY))\n",
        "  print(confusion_matrix(testY, predY))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_oQ9RvA0oyM",
        "outputId": "a3a06709-2685-47b8-fa04-cccd208ec81d"
      },
      "source": [
        "linear_svm = LinearSVC(C=2)\n",
        "train_and_test(linear_svm)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9964791615491689\n",
            "Precision: 0.9979959919839679\n",
            "Recall: 0.9934171154997008\n",
            "F1Score: 0.9957012896131161\n",
            "[[7190   10]\n",
            " [  33 4980]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NzETshJpzF2Y",
        "outputId": "d61efd7b-7e05-4fb2-dc2a-d7f4b6fe03d1"
      },
      "source": [
        "rfc = RandomForestClassifier(n_estimators=32)\n",
        "train_and_test(rfc)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.970195693113895\n",
            "Precision: 0.9408306466906884\n",
            "Recall: 0.9896269698783163\n",
            "F1Score: 0.9646120941084969\n",
            "[[6888  312]\n",
            " [  52 4961]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64cSSb-fevw7",
        "outputId": "0c46858d-498c-4407-9b88-a1983d1c3629"
      },
      "source": [
        "xgb =  XGBClassifier(\n",
        "            learning_rate=0.3,\n",
        "            n_estimators=500,\n",
        "            max_depth=6,\n",
        "            min_child_weight=1,\n",
        "            gamma=0.3,\n",
        "            subsample=0.8,\n",
        "            colsample_bytree=0.9,\n",
        "            objective= 'binary:logistic',\n",
        "            nthread=-1,\n",
        "            scale_pos_weight=1,\n",
        ")\n",
        "\n",
        "train_and_test(xgb)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9667567346270368\n",
            "Precision: 0.9398510597670422\n",
            "Recall: 0.9818471972870536\n",
            "F1Score: 0.960390243902439\n",
            "[[6885  315]\n",
            " [  91 4922]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "keiOOK7Kfn1Q",
        "outputId": "7571f492-dedb-4684-ab0a-96fe00e5c276"
      },
      "source": [
        "lgbm = LGBMClassifier(n_estimators=400, learning_rate=0.3)\n",
        "train_and_test(lgbm)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9700319331859494\n",
            "Precision: 0.9431623116536334\n",
            "Recall: 0.9864352683024137\n",
            "F1Score: 0.9643135725429017\n",
            "[[6902  298]\n",
            " [  68 4945]]\n"
          ]
        }
      ]
    }
  ]
}